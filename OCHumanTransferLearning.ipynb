{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-20T04:27:52.021534Z",
     "start_time": "2023-10-20T04:27:38.064126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.1.0\r\n",
      "Uninstalling torch-2.1.0:\r\n",
      "  Successfully uninstalled torch-2.1.0\r\n",
      "Found existing installation: torchvision 0.16.0\r\n",
      "Uninstalling torchvision-0.16.0:\r\n",
      "  Successfully uninstalled torchvision-0.16.0\r\n",
      "Collecting torch==2.1.0\r\n",
      "  Obtaining dependency information for torch==2.1.0 from https://files.pythonhosted.org/packages/4c/53/f1e58e147df8601c963df4b15045631f7e3d3caa5973bdf4e54a5cf6834e/torch-2.1.0-cp39-none-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached torch-2.1.0-cp39-none-macosx_11_0_arm64.whl.metadata (24 kB)\r\n",
      "Requirement already satisfied: filelock in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from torch==2.1.0) (3.12.4)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from torch==2.1.0) (4.7.1)\r\n",
      "Requirement already satisfied: sympy in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from torch==2.1.0) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from torch==2.1.0) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from torch==2.1.0) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from torch==2.1.0) (2023.9.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from jinja2->torch==2.1.0) (2.1.1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from sympy->torch==2.1.0) (1.3.0)\r\n",
      "Using cached torch-2.1.0-cp39-none-macosx_11_0_arm64.whl (59.5 MB)\r\n",
      "Installing collected packages: torch\r\n",
      "Successfully installed torch-2.1.0\r\n",
      "Collecting torchvision==0.16.0\r\n",
      "  Obtaining dependency information for torchvision==0.16.0 from https://files.pythonhosted.org/packages/7d/fd/9c2b3d0200532dc4a6211ef0fcf78c0556a27e3b03800333d4caa32bedc5/torchvision-0.16.0-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached torchvision-0.16.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: numpy in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from torchvision==0.16.0) (1.24.3)\r\n",
      "Requirement already satisfied: requests in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from torchvision==0.16.0) (2.31.0)\r\n",
      "Requirement already satisfied: torch==2.1.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from torchvision==0.16.0) (2.1.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from torchvision==0.16.0) (9.4.0)\r\n",
      "Requirement already satisfied: filelock in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from torch==2.1.0->torchvision==0.16.0) (3.12.4)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from torch==2.1.0->torchvision==0.16.0) (4.7.1)\r\n",
      "Requirement already satisfied: sympy in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from torch==2.1.0->torchvision==0.16.0) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from torch==2.1.0->torchvision==0.16.0) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from torch==2.1.0->torchvision==0.16.0) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from torch==2.1.0->torchvision==0.16.0) (2023.9.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from requests->torchvision==0.16.0) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from requests->torchvision==0.16.0) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from requests->torchvision==0.16.0) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from requests->torchvision==0.16.0) (2023.7.22)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from jinja2->torch==2.1.0->torchvision==0.16.0) (2.1.1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from sympy->torch==2.1.0->torchvision==0.16.0) (1.3.0)\r\n",
      "Using cached torchvision-0.16.0-cp39-cp39-macosx_11_0_arm64.whl (1.6 MB)\r\n",
      "Installing collected packages: torchvision\r\n",
      "Successfully installed torchvision-0.16.0\r\n"
     ]
    },
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x108dc01b0>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip uninstall torch -y\n",
    "!pip uninstall torchvision -y\n",
    "!pip install torch==2.1.0\n",
    "!pip install torchvision==0.16.0\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ochumanApi.ochuman import Poly2Mask\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import tv_tensors\n",
    "from ochumanApi.ochuman import OCHuman\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15, 15)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "\n",
    "class OCHumanDataset(Dataset):\n",
    "    def __init__(self, image_root: str, oc_human: OCHuman):\n",
    "        self.root = image_root\n",
    "        self.data = oc_human.loadImgs(imgIds=oc_human.getImgIds())\n",
    "        self.images, self.masks, self.bounding_boxes = self.__get_properties(oc_human_data=self.data)\n",
    "        self.__getitem__(2)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]/255\n",
    "        masks = self.masks[index]\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "        \n",
    "        number_of_objects = len(masks)\n",
    "        \n",
    "        labels = torch.ones(number_of_objects, dtype=torch.int64)\n",
    "        \n",
    "        bounding_boxes = torch.as_tensor(self.bounding_boxes[index][:])\n",
    "        area = torch.as_tensor(self.__get_areas(index))\n",
    "        \n",
    "        image_id = index\n",
    "        \n",
    "        is_crowd = torch.zeros(number_of_objects, dtype=torch.int64)\n",
    "        \n",
    "        target = {'boxes': bounding_boxes,\n",
    "                  'masks': masks, 'labels': labels, 'image_id': image_id, 'area': area,\n",
    "                  'iscrowd': is_crowd}\n",
    "        return image, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __get_properties(self, oc_human_data):\n",
    "        images = []\n",
    "        image_masks = []\n",
    "        bounding_boxes = []\n",
    "        for file in oc_human_data:\n",
    "            images.append(read_image(os.path.join(self.root, file['file_name']), mode=ImageReadMode.RGB))\n",
    "            image_masks.append(self.__get_binary_masks(file=file))\n",
    "            bounding_boxes.append(self.__get_bounding_boxes(file=file))\n",
    "        return images, image_masks, bounding_boxes\n",
    "    \n",
    "    @staticmethod\n",
    "    def __get_binary_masks(file):\n",
    "        masks = []\n",
    "        for annotation in file['annotations']:\n",
    "            segmentation = annotation['segms']\n",
    "            if segmentation is not None:\n",
    "                masks.append(Poly2Mask(segmentation))\n",
    "        return masks\n",
    "        \n",
    "    @staticmethod\n",
    "    def __get_bounding_boxes(file):\n",
    "        bounding_boxes = []\n",
    "        for annotation in file['annotations']:\n",
    "            bounding_box = annotation['bbox']\n",
    "            if bounding_box is not None:\n",
    "                bounding_boxes.append(bounding_box)\n",
    "        return bounding_boxes\n",
    "    \n",
    "    def __get_areas(self, index):\n",
    "        bounding_boxes = self.bounding_boxes[index][:][:]\n",
    "        areas = []\n",
    "        for box in bounding_boxes:\n",
    "            areas.append((box[3] - box[1]) * (box[2] - box[0]))\n",
    "        return np.array(areas)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T04:27:52.030836Z",
     "start_time": "2023-10-20T04:27:52.025878Z"
    }
   },
   "id": "cebe9d215aa9f4a5"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 0/50]  eta: 2:10:24  lr: 0.000107  loss: 2.6470 (2.6470)  loss_classifier: 0.6061 (0.6061)  loss_box_reg: 0.1605 (0.1605)  loss_mask: 1.8647 (1.8647)  loss_objectness: 0.0112 (0.0112)  loss_rpn_box_reg: 0.0046 (0.0046)  time: 156.4876  data: 0.3110\n",
      "Epoch: [0]  [10/50]  eta: 0:49:06  lr: 0.001126  loss: 2.0396 (1.8897)  loss_classifier: 0.4635 (0.4190)  loss_box_reg: 0.1315 (0.1390)  loss_mask: 1.3813 (1.2967)  loss_objectness: 0.0225 (0.0207)  loss_rpn_box_reg: 0.0117 (0.0143)  time: 73.6562  data: 0.3222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-10-19 23:49:39,543] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (64)\n",
      "[2023-10-19 23:49:39,543] torch._dynamo.convert_frame: [WARNING]    function: '<resume in resize>' (/Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages/torchvision/models/detection/transform.py:186)\n",
      "[2023-10-19 23:49:39,543] torch._dynamo.convert_frame: [WARNING] to diagnose recompilation issues, set env variable TORCHDYNAMO_REPORT_GUARD_FAILURES=1 and also see https://pytorch.org/docs/master/compile/troubleshooting.html.\n",
      "[2023-10-19 23:49:39,547] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (64)\n",
      "[2023-10-19 23:49:39,547] torch._dynamo.convert_frame: [WARNING]    function: '_resize_image_and_masks' (/Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages/torchvision/models/detection/transform.py:25)\n",
      "[2023-10-19 23:49:39,547] torch._dynamo.convert_frame: [WARNING] to diagnose recompilation issues, set env variable TORCHDYNAMO_REPORT_GUARD_FAILURES=1 and also see https://pytorch.org/docs/master/compile/troubleshooting.html.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [20/50]  eta: 0:27:19  lr: 0.002146  loss: 1.0801 (1.4711)  loss_classifier: 0.1262 (0.2714)  loss_box_reg: 0.1358 (0.1380)  loss_mask: 0.7860 (1.0313)  loss_objectness: 0.0187 (0.0193)  loss_rpn_box_reg: 0.0073 (0.0112)  time: 49.5455  data: 0.3152\n",
      "Epoch: [0]  [30/50]  eta: 0:15:28  lr: 0.003165  loss: 0.9399 (1.2784)  loss_classifier: 0.0975 (0.2095)  loss_box_reg: 0.1319 (0.1323)  loss_mask: 0.6764 (0.9061)  loss_objectness: 0.0149 (0.0176)  loss_rpn_box_reg: 0.0077 (0.0128)  time: 31.4182  data: 0.3002\n",
      "Epoch: [0]  [40/50]  eta: 0:06:59  lr: 0.004184  loss: 0.7669 (1.1343)  loss_classifier: 0.0612 (0.1706)  loss_box_reg: 0.1196 (0.1292)  loss_mask: 0.5352 (0.8073)  loss_objectness: 0.0111 (0.0156)  loss_rpn_box_reg: 0.0094 (0.0116)  time: 28.6866  data: 0.2936\n",
      "Epoch: [0]  [49/50]  eta: 0:00:39  lr: 0.005000  loss: 0.6794 (1.0465)  loss_classifier: 0.0447 (0.1471)  loss_box_reg: 0.1215 (0.1279)  loss_mask: 0.4809 (0.7449)  loss_objectness: 0.0095 (0.0146)  loss_rpn_box_reg: 0.0090 (0.0119)  time: 28.9030  data: 0.2954\n",
      "Epoch: [0] Total time: 0:33:07 (39.7433 s / it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT forward /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages/torchvision/models/detection/rpn.py line 335 \n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING]   File \"/Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages/torch/_refs/__init__.py\", line 1874, in where\n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING]     raise NotImplementedError\n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.TorchRuntimeError: Failed running call_function <built-in method where of type object at 0x10a379790>(*(FakeTensor(..., size=(3*s8*s9 + 4000,), dtype=torch.bool),), **{}):\n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING] \n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING] \n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING] from user code:\n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING]    File \"/Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages/torchvision/models/detection/rpn.py\", line 372, in forward\n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING]     boxes, scores = self.filter_proposals(proposals, objectness, images.image_sizes, num_anchors_per_level)\n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING]   File \"/Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages/torchvision/models/detection/rpn.py\", line 279, in filter_proposals\n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING]     keep = box_ops.remove_small_boxes(boxes, self.min_size)\n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING]   File \"/Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages/torchvision/ops/boxes.py\", line 132, in remove_small_boxes\n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING]     keep = torch.where(keep)[0]\n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING] \n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING] \n",
      "[2023-10-20 00:12:45,315] torch._dynamo.convert_frame: [WARNING] \n",
      "[2023-10-20 00:12:46,659] [74/0] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:12:48,688] [75/0] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat_1\n",
      "[2023-10-20 00:12:48,689] [75/0] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:12:49,901] [76/0] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:12:51,052] [28/29] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:12:51,053] [28/29] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:12:51,390] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT remove_small_boxes /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages/torchvision/ops/boxes.py line 115 \n",
      "[2023-10-20 00:12:51,390] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2023-10-20 00:12:51,390] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2023-10-20 00:12:51,390] torch._dynamo.convert_frame: [WARNING]   File \"/Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages/torch/_refs/__init__.py\", line 1874, in where\n",
      "[2023-10-20 00:12:51,390] torch._dynamo.convert_frame: [WARNING]     raise NotImplementedError\n",
      "[2023-10-20 00:12:51,390] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.TorchRuntimeError: Failed running call_function <built-in method where of type object at 0x10a379790>(*(FakeTensor(..., size=(s0,), dtype=torch.bool),), **{}):\n",
      "[2023-10-20 00:12:51,390] torch._dynamo.convert_frame: [WARNING] \n",
      "[2023-10-20 00:12:51,390] torch._dynamo.convert_frame: [WARNING] \n",
      "[2023-10-20 00:12:51,390] torch._dynamo.convert_frame: [WARNING] from user code:\n",
      "[2023-10-20 00:12:51,390] torch._dynamo.convert_frame: [WARNING]    File \"/Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages/torchvision/ops/boxes.py\", line 132, in remove_small_boxes\n",
      "[2023-10-20 00:12:51,390] torch._dynamo.convert_frame: [WARNING]     keep = torch.where(keep)[0]\n",
      "[2023-10-20 00:12:51,390] torch._dynamo.convert_frame: [WARNING] \n",
      "[2023-10-20 00:12:51,390] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2023-10-20 00:12:51,390] torch._dynamo.convert_frame: [WARNING] \n",
      "[2023-10-20 00:12:51,390] torch._dynamo.convert_frame: [WARNING] \n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT forward /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages/torchvision/models/detection/roi_heads.py line 727 \n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING]   File \"/Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages/torch/_refs/__init__.py\", line 1874, in where\n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING]     raise NotImplementedError\n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.TorchRuntimeError: Failed running call_function <built-in method where of type object at 0x10a379790>(*(FakeTensor(..., size=(s10,), dtype=torch.bool),), **{}):\n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING] \n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING] \n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING] from user code:\n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING]    File \"/Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages/torchvision/models/detection/roi_heads.py\", line 761, in forward\n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING]     box_features = self.box_roi_pool(features, proposals, image_shapes)\n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING]   File \"/Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING]     return forward_call(*args, **kwargs)\n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING]   File \"/Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages/torchvision/ops/poolers.py\", line 314, in forward\n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING]     return _multiscale_roi_align(\n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING]   File \"/Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages/torchvision/ops/poolers.py\", line 201, in _multiscale_roi_align\n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING]     idx_in_level = torch.where(levels == level)[0]\n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING] \n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING] \n",
      "[2023-10-20 00:12:51,596] torch._dynamo.convert_frame: [WARNING] \n",
      "[2023-10-20 00:12:51,617] [61/3] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat_2\n",
      "[2023-10-20 00:12:51,617] [61/3] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat_1\n",
      "[2023-10-20 00:12:51,618] [61/3] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:12:51,724] [62/3] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:12:55,045] [76/1] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:12:57,385] [81/0] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:12:57,386] [81/0] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [ 0/50]  eta: 0:20:58  model_time: 25.0882 (25.0882)  evaluator_time: 0.0140 (0.0140)  time: 25.1705  data: 0.0683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-10-20 00:13:09,315] [74/1] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:13:10,508] [76/2] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:13:11,078] [28/30] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:13:11,079] [28/30] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:13:12,820] [81/1] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:13:12,820] [81/1] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:13:25,943] [74/2] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:13:27,068] [28/31] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:13:27,069] [28/31] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:13:28,174] [81/2] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:13:28,175] [81/2] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:13:33,038] [81/3] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:13:33,039] [81/3] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:13:38,427] [28/32] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:13:38,427] [28/32] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:13:39,478] [81/4] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:13:39,479] [81/4] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:13:42,813] [81/5] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:13:42,814] [81/5] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:13:46,389] [28/33] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:13:46,390] [28/33] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:13:47,502] [81/6] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:13:47,503] [81/6] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:13:58,290] [81/7] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:13:58,291] [81/7] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:14:01,125] [28/34] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:14:01,126] [28/34] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:14:02,164] [81/8] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:14:02,165] [81/8] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:14:04,248] [28/35] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:14:04,248] [28/35] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:14:09,565] [28/36] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:14:09,565] [28/36] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:14:10,553] [81/9] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:14:10,554] [81/9] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:14:14,256] [81/10] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:14:14,257] [81/10] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:14:24,293] [28/37] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:14:24,294] [28/37] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:14:25,527] [81/11] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:14:25,527] [81/11] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:14:29,849] [81/12] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:14:29,850] [81/12] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:14:34,351] [81/13] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:14:34,352] [81/13] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:14:48,207] [81/14] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:14:48,208] [81/14] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:14:53,038] [28/38] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:14:53,039] [28/38] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:14:56,102] [28/39] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:14:56,103] [28/39] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:14:57,163] [81/15] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:14:57,164] [81/15] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:15:07,160] [81/16] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:15:07,161] [81/16] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:15:10,616] [81/17] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:15:10,616] [81/17] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:15:19,032] [81/18] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:15:19,033] [81/18] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:15:27,682] [28/40] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:15:27,682] [28/40] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:15:39,217] [81/19] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:15:39,218] [81/19] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:15:44,645] [81/20] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:15:44,646] [81/20] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:16:06,735] [81/21] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:16:06,736] [81/21] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "Training Epoch:  50%|█████     | 1/2 [42:14<42:14, 2534.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [49/50]  eta: 0:00:04  model_time: 2.5637 (4.4011)  evaluator_time: 0.0165 (0.0178)  time: 3.2228  data: 0.0601\n",
      "Test: Total time: 0:03:44 (4.4813 s / it)\n",
      "Averaged stats: model_time: 2.5637 (4.4011)  evaluator_time: 0.0165 (0.0178)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.704\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.520\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.521\n",
      "IoU metric: segm\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.356\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.096\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.341\n",
      "Epoch: [1]  [ 0/50]  eta: 0:31:01  lr: 0.005000  loss: 0.6187 (0.6187)  loss_classifier: 0.0256 (0.0256)  loss_box_reg: 0.0632 (0.0632)  loss_mask: 0.5032 (0.5032)  loss_objectness: 0.0060 (0.0060)  loss_rpn_box_reg: 0.0208 (0.0208)  time: 37.2243  data: 0.2635\n",
      "Epoch: [1]  [10/50]  eta: 0:18:22  lr: 0.005000  loss: 0.5817 (0.5675)  loss_classifier: 0.0317 (0.0310)  loss_box_reg: 0.1109 (0.1046)  loss_mask: 0.4113 (0.4171)  loss_objectness: 0.0060 (0.0069)  loss_rpn_box_reg: 0.0071 (0.0078)  time: 27.5508  data: 0.3175\n",
      "Epoch: [1]  [20/50]  eta: 0:13:11  lr: 0.005000  loss: 0.5539 (0.5873)  loss_classifier: 0.0298 (0.0300)  loss_box_reg: 0.0974 (0.0977)  loss_mask: 0.4113 (0.4428)  loss_objectness: 0.0053 (0.0067)  loss_rpn_box_reg: 0.0079 (0.0101)  time: 25.8454  data: 0.3016\n",
      "Epoch: [1]  [30/50]  eta: 0:08:51  lr: 0.005000  loss: 0.5435 (0.5717)  loss_classifier: 0.0298 (0.0298)  loss_box_reg: 0.0839 (0.0924)  loss_mask: 0.4142 (0.4349)  loss_objectness: 0.0037 (0.0058)  loss_rpn_box_reg: 0.0076 (0.0088)  time: 26.0694  data: 0.2748\n",
      "Epoch: [1]  [40/50]  eta: 0:04:21  lr: 0.005000  loss: 0.5422 (0.5609)  loss_classifier: 0.0305 (0.0299)  loss_box_reg: 0.0771 (0.0883)  loss_mask: 0.3937 (0.4269)  loss_objectness: 0.0027 (0.0053)  loss_rpn_box_reg: 0.0091 (0.0105)  time: 25.9772  data: 0.2914\n",
      "Epoch: [1]  [49/50]  eta: 0:00:25  lr: 0.005000  loss: 0.5166 (0.5514)  loss_classifier: 0.0284 (0.0301)  loss_box_reg: 0.0680 (0.0835)  loss_mask: 0.3976 (0.4231)  loss_objectness: 0.0027 (0.0050)  loss_rpn_box_reg: 0.0084 (0.0098)  time: 25.2093  data: 0.2999\n",
      "Epoch: [1] Total time: 0:21:34 (25.8860 s / it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/50]  eta: 0:02:21  model_time: 2.7487 (2.7487)  evaluator_time: 0.0106 (0.0106)  time: 2.8269  data: 0.0675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-10-20 00:43:29,365] [81/22] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:43:29,366] [81/22] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:43:34,224] [81/23] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:43:34,225] [81/23] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:43:45,548] [81/24] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:43:45,548] [81/24] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:43:50,075] [81/25] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:43:50,076] [81/25] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:44:13,220] [81/26] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:44:13,221] [81/26] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "[2023-10-20 00:44:54,919] [81/27] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: split\n",
      "[2023-10-20 00:44:54,920] [81/27] torch._inductor.fx_passes.split_cat: [WARNING] example value absent for node: cat\n",
      "Training Epoch: 100%|██████████| 2/2 [1:10:49<00:00, 2124.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [49/50]  eta: 0:00:01  model_time: 1.5203 (1.8587)  evaluator_time: 0.0081 (0.0104)  time: 1.6710  data: 0.0609\n",
      "Test: Total time: 0:01:36 (1.9314 s / it)\n",
      "Averaged stats: model_time: 1.5203 (1.8587)  evaluator_time: 0.0081 (0.0104)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.726\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.499\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.499\n",
      "IoU metric: segm\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.116\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.349\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.018\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from engine import train_one_epoch, evaluate\n",
    "from tqdm import trange\n",
    "from datetime import datetime\n",
    "\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "ochuman = OCHuman(AnnoFile='./ochuman.json', Filter='kpt&segm')\n",
    "\n",
    "dataset = OCHumanDataset(image_root='./images/', oc_human=ochuman)\n",
    "dataset_test = OCHumanDataset(image_root='./images/', oc_human=ochuman)\n",
    "\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset_train = torch.utils.data.Subset(dataset, indices[:200])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[201:251])\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(weights='DEFAULT')\n",
    "\n",
    "number_of_classes = 2\n",
    "\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, number_of_classes)\n",
    "\n",
    "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "hidden_layer = 256\n",
    "    \n",
    "model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "    in_features_mask,\n",
    "    hidden_layer,\n",
    "    number_of_classes,\n",
    ")\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.compile()\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    params,\n",
    "    lr=0.005,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005\n",
    ")\n",
    "\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=3,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "def get_current_time():\n",
    "    now = datetime.now()\n",
    "    now = now.strftime(\"%b-%d-%Y %H:%M:%S\")\n",
    "    return now\n",
    "\n",
    "def save_model(current_model, time, directory):\n",
    "    model_scripted = torch.jit.script(current_model) \n",
    "    model_scripted.save(directory + '/checkpoint ' + time + '.pt')\n",
    "    \n",
    "filename = \"run \" + get_current_time()\n",
    "run_directory = \"runs/\" + filename\n",
    "os.mkdir(run_directory)\n",
    "\n",
    "for epoch in trange(num_epochs, desc='Training Epoch'):\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "    save_model(model, get_current_time(), run_directory)\n",
    "    lr_scheduler.step()\n",
    "    evaluate(model, data_loader_test, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T05:44:56.410650Z",
     "start_time": "2023-10-20T04:33:23.247376Z"
    }
   },
   "id": "f9380608591c7038"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3e53eb0b6b3db98d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
