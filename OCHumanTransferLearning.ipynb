{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-22T04:37:58.819983Z",
     "start_time": "2023-12-22T04:37:50.814747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/detectron2.git\r\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to /private/var/folders/_t/s7kkvk9540n3cp76z802ksnh0000gp/T/pip-req-build-t18dzrr4\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /private/var/folders/_t/s7kkvk9540n3cp76z802ksnh0000gp/T/pip-req-build-t18dzrr4\r\n",
      "  Resolved https://github.com/facebookresearch/detectron2.git to commit e9f7e2ba15abd7badcb05ef6f5076f06b36a9c5b\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: Pillow>=7.1 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from detectron2==0.6) (9.4.0)\r\n",
      "Requirement already satisfied: matplotlib in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from detectron2==0.6) (3.7.2)\r\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from detectron2==0.6) (2.0.6)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from detectron2==0.6) (2.1.0)\r\n",
      "Requirement already satisfied: yacs>=0.1.8 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from detectron2==0.6) (0.1.8)\r\n",
      "Requirement already satisfied: tabulate in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from detectron2==0.6) (0.8.10)\r\n",
      "Requirement already satisfied: cloudpickle in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from detectron2==0.6) (2.2.1)\r\n",
      "Requirement already satisfied: tqdm>4.29.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from detectron2==0.6) (4.65.0)\r\n",
      "Requirement already satisfied: tensorboard in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from detectron2==0.6) (2.11.0)\r\n",
      "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from detectron2==0.6) (0.1.5.post20221221)\r\n",
      "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from detectron2==0.6) (0.1.9)\r\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.1 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from detectron2==0.6) (2.1.1)\r\n",
      "Requirement already satisfied: hydra-core>=1.1 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from detectron2==0.6) (1.1.0)\r\n",
      "Requirement already satisfied: black in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from detectron2==0.6) (23.11.0)\r\n",
      "Requirement already satisfied: packaging in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from detectron2==0.6) (23.1)\r\n",
      "Requirement already satisfied: numpy in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.24.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0)\r\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from hydra-core>=1.1->detectron2==0.6) (4.8)\r\n",
      "Requirement already satisfied: portalocker in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.3.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from matplotlib->detectron2==0.6) (1.0.5)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from matplotlib->detectron2==0.6) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from matplotlib->detectron2==0.6) (4.25.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from matplotlib->detectron2==0.6) (1.4.4)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from matplotlib->detectron2==0.6) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from matplotlib->detectron2==0.6) (2.8.2)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from matplotlib->detectron2==0.6) (5.2.0)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from black->detectron2==0.6) (8.0.4)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from black->detectron2==0.6) (1.0.0)\r\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from black->detectron2==0.6) (0.11.2)\r\n",
      "Requirement already satisfied: platformdirs>=2 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from black->detectron2==0.6) (3.10.0)\r\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from black->detectron2==0.6) (2.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from black->detectron2==0.6) (4.7.1)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (1.4.0)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (1.42.0)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (2.22.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (0.4.4)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (3.4.1)\r\n",
      "Requirement already satisfied: protobuf<4,>=3.9.2 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (3.20.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (2.31.0)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (68.0.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (0.6.1)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (1.8.1)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (2.2.3)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (0.35.1)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.2.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.8)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.7.2)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (1.16.0)\r\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (1.26.16)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->detectron2==0.6) (3.11.0)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard->detectron2==0.6) (6.0.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2023.11.17)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.1)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.2.2)\r\n"
     ]
    },
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x11d048550>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from ochumanApi.ochuman import Poly2Mask\n",
    "from torch.utils.data import Dataset\n",
    "from ochumanApi.ochuman import OCHuman\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15, 15)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torchvision.ops.boxes import masks_to_boxes\n",
    "from torchvision.tv_tensors import BoundingBoxes, Mask\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.transforms.v2 import functional as F, Transform\n",
    "\n",
    "\n",
    "class OCHumanDataset(Dataset):\n",
    "    def __init__(self, image_root: str, oc_human_object: OCHuman, transforms):\n",
    "        self.root = image_root\n",
    "        self.data = oc_human_object.loadImgs(imgIds=oc_human_object.getImgIds())\n",
    "        self.images, self.masks = self.__get_properties(oc_human_data=self.data)\n",
    "        self.transforms = transforms\n",
    "        self.__getitem__(2)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # image = self.images[index]/255\n",
    "        # masks = self.masks[index]\n",
    "        # masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "        # \n",
    "        # number_of_objects = len(masks)\n",
    "        # \n",
    "        # labels = torch.ones(number_of_objects, dtype=torch.int64)\n",
    "        # \n",
    "        # bounding_boxes = torch.as_tensor(self.bounding_boxes[index][:])\n",
    "        # area = torch.as_tensor(self.__get_areas(index))\n",
    "        # \n",
    "        # image_id = index\n",
    "        # \n",
    "        # is_crowd = torch.zeros(number_of_objects, dtype=torch.int64)\n",
    "        # \n",
    "        # canvas_size = image.size()\n",
    "        # \n",
    "        # target = {'boxes': BoundingBoxes(bounding_boxes, format='XYXY', canvas_size=canvas_size[1:]),\n",
    "        #           'masks': Mask(masks), 'labels': labels, 'image_id': image_id, 'area': area,\n",
    "        #           'iscrowd': is_crowd}\n",
    "        image = self.images[index]/255\n",
    "        masks = self.masks[index]\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        number_of_objects = len(masks)\n",
    "\n",
    "        labels = torch.ones(number_of_objects, dtype=torch.int64)\n",
    "\n",
    "        bounding_boxes = masks_to_boxes(masks=masks)\n",
    "        area = (bounding_boxes[:, 3] - bounding_boxes[:, 1]) * (bounding_boxes[:, 2] - bounding_boxes[:, 0])\n",
    "\n",
    "        image_id = torch.as_tensor(index, dtype=torch.int64)\n",
    "\n",
    "        is_crowd = torch.zeros(number_of_objects, dtype=torch.uint8)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = tv_tensors.BoundingBoxes(bounding_boxes, format=\"XYXY\", canvas_size=F.get_size(image))\n",
    "        target[\"masks\"] = tv_tensors.Mask(masks)\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = is_crowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(image, target)\n",
    "\n",
    "        return image, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __get_properties(self, oc_human_data):\n",
    "        images = []\n",
    "        image_masks = []\n",
    "        for file in oc_human_data:\n",
    "            images.append(read_image(os.path.join(self.root, file['file_name']), mode=ImageReadMode.RGB))\n",
    "            image_masks.append(self.__get_binary_masks(file=file))\n",
    "        return images, image_masks\n",
    "    \n",
    "    @staticmethod\n",
    "    def __get_binary_masks(file):\n",
    "        masks = []\n",
    "        for annotation in file['annotations']:\n",
    "            segmentation = annotation['segms']\n",
    "            if segmentation is not None:\n",
    "                masks.append(Poly2Mask(segmentation))\n",
    "        return masks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T04:38:39.613982Z",
     "start_time": "2023-12-22T04:38:39.607290Z"
    }
   },
   "id": "cebe9d215aa9f4a5"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from engine import train_one_epoch, evaluate\n",
    "from tqdm import trange\n",
    "from datetime import datetime\n",
    "\n",
    "oc_human = OCHuman(AnnoFile='./ochuman.json', Filter='kpt&segm')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T04:38:43.171845Z",
     "start_time": "2023-12-22T04:38:42.457024Z"
    }
   },
   "id": "fd3e1ab184e7a659"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_t/s7kkvk9540n3cp76z802ksnh0000gp/T/ipykernel_20420/756242265.py:41: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:264.)\n",
      "  masks = torch.as_tensor(masks, dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import v2 as T\n",
    "\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "    transforms.append(T.ToPureTensor())\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "dataset = OCHumanDataset(image_root='images/', oc_human_object=oc_human, transforms=get_transform(train=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T04:39:04.869392Z",
     "start_time": "2023-12-22T04:38:48.092600Z"
    }
   },
   "id": "d1d962c2da059983"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rouna/anaconda3/envs/thirdlama/lib/python3.9/site-packages/google/colab/data_table.py:30: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  from IPython.utils import traitlets as _traitlets\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpatches\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cv2_imshow\n\u001B[0;32m----> 2\u001B[0m masks \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m[\u001B[38;5;241m17\u001B[39m][\u001B[38;5;241m1\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmasks\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mask \u001B[38;5;129;01min\u001B[39;00m masks:\n\u001B[1;32m      4\u001B[0m     cv2_imshow(mask\u001B[38;5;241m.\u001B[39mnumpy() \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m255\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "masks = dataset[17][1]['masks']\n",
    "for mask in masks:\n",
    "    cv2_imshow(mask.numpy() * 255)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T04:38:24.874435Z",
     "start_time": "2023-12-22T04:38:23.138828Z"
    }
   },
   "id": "6b982d1790e57bc2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "\n",
    "dataset_train = torch.utils.data.Subset(dataset, indices[:5])\n",
    "\n",
    "dataset_validation = torch.utils.data.Subset(dataset, indices[3001:3002])\n",
    "\n",
    "dataset_test = torch.utils.data.Subset(dataset, indices[4001:4002])\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "data_loader_validation = torch.utils.data.DataLoader (\n",
    "    dataset_validation,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    collate_fn=utils.collate_fn\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ac59ca970a9c0bd"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(weights='DEFAULT')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T10:08:17.631677Z",
     "start_time": "2023-11-12T10:08:17.023909Z"
    }
   },
   "id": "75141c120c839ecb"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RoIHeads' object has no attribute 'maskrcnn_loss'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroi_heads\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaskrcnn_loss\u001B[49m)\n",
      "File \u001B[0;32m~/anaconda3/envs/thirdlama/lib/python3.9/site-packages/torch/nn/modules/module.py:1695\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1693\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[1;32m   1694\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[0;32m-> 1695\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'RoIHeads' object has no attribute 'maskrcnn_loss'"
     ]
    }
   ],
   "source": [
    "number_of_classes = 2\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(model.roi_heads.maskrcnn_loss)\n",
    "\n",
    "# in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# \n",
    "# model.roi_heads.box_predictor = FastRCNNPredictor(in_features, number_of_classes)\n",
    "# \n",
    "# in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "# hidden_layer = 256\n",
    "#     \n",
    "# model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "#     in_features_mask,\n",
    "#     hidden_layer,\n",
    "#     number_of_classes,\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T10:08:19.421566Z",
     "start_time": "2023-11-12T10:08:19.212729Z"
    }
   },
   "id": "f21fd10a7bf4480e"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 14\u001B[0m\n\u001B[1;32m     10\u001B[0m torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39msuppress_errors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     12\u001B[0m ochuman \u001B[38;5;241m=\u001B[39m OCHuman(AnnoFile\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./ochuman.json\u001B[39m\u001B[38;5;124m'\u001B[39m, Filter\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkpt&segm\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 14\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mOCHumanDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_root\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./images/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moc_human\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mochuman\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m dataset_test \u001B[38;5;241m=\u001B[39m OCHumanDataset(image_root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./images/\u001B[39m\u001B[38;5;124m'\u001B[39m, oc_human\u001B[38;5;241m=\u001B[39mochuman)\n\u001B[1;32m     17\u001B[0m indices \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandperm(\u001B[38;5;28mlen\u001B[39m(dataset))\u001B[38;5;241m.\u001B[39mtolist()\n",
      "Cell \u001B[0;32mIn[8], line 13\u001B[0m, in \u001B[0;36mOCHumanDataset.__init__\u001B[0;34m(self, image_root, oc_human)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m oc_human\u001B[38;5;241m.\u001B[39mloadImgs(imgIds\u001B[38;5;241m=\u001B[39moc_human\u001B[38;5;241m.\u001B[39mgetImgIds())\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimages, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmasks, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbounding_boxes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_properties(oc_human_data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata)\n\u001B[0;32m---> 13\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getitem__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[8], line 17\u001B[0m, in \u001B[0;36mOCHumanDataset.__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index):\n\u001B[1;32m     16\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimages[index]\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m255\u001B[39m\n\u001B[0;32m---> 17\u001B[0m     \u001B[43mcv2_imshow\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimages\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m     masks \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmasks[index])\n\u001B[1;32m     19\u001B[0m     masks \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mas_tensor(masks, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39muint8)\n",
      "File \u001B[0;32m~/anaconda3/envs/thirdlama/lib/python3.9/site-packages/google/colab/patches/__init__.py:22\u001B[0m, in \u001B[0;36mcv2_imshow\u001B[0;34m(a)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcv2_imshow\u001B[39m(a):\n\u001B[1;32m     15\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"A replacement for cv2.imshow() for use in Jupyter notebooks.\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \n\u001B[1;32m     17\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;124;03m      image.\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m   a \u001B[38;5;241m=\u001B[39m \u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclip\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m255\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muint8\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     23\u001B[0m   \u001B[38;5;66;03m# cv2 stores colors as BGR; convert to RGB\u001B[39;00m\n\u001B[1;32m     24\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m a\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m:\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Tensor' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    params,\n",
    "    lr=0.005,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005\n",
    ")\n",
    "\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=3,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "def get_current_time():\n",
    "    now = datetime.now()\n",
    "    now = now.strftime(\"%b-%d-%Y_%H-%M-%S\")\n",
    "    return now\n",
    "\n",
    "def save_model(current_model, time, directory):\n",
    "    model_scripted = torch.jit.script(current_model) \n",
    "    model_scripted.save(directory + '/checkpoint_' + time + '.pt')\n",
    "    \n",
    "filename = \"run_\" + get_current_time()\n",
    "run_directory = \"/storage/runs/\" + filename\n",
    "os.mkdir(run_directory)\n",
    "\n",
    "evaluate(model, data_loader_validation, device=device)\n",
    "\n",
    "for epoch in trange(num_epochs, desc='Training Epoch'):\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=500)\n",
    "    save_model(model, get_current_time(), run_directory)\n",
    "    lr_scheduler.step()\n",
    "    with torch.no_grad():\n",
    "        evaluate(model, data_loader_validation, device=device)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    evaluate(model, data_loader_test, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T18:28:33.991236Z"
    }
   },
   "id": "f9380608591c7038"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3e53eb0b6b3db98d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
